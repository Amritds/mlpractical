{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from data_providers import MNISTDataProvider\n",
    "from data_providers import  CIFAR100DataProvider\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "seed=1\n",
    "rng = np.random.RandomState(seed=seed)  # set seed\n",
    "train_data = CIFAR100DataProvider(which_set=\"train\", batch_size=batch_size, rng=rng, random_sampling=True)\n",
    "val_data = CIFAR100DataProvider(which_set=\"valid\", batch_size=batch_size, rng=rng)\n",
    "test_data = CIFAR100DataProvider(which_set=\"test\", batch_size=batch_size, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "centroid = list(np.zeros((100)))\n",
    "for c in np.arange(100):\n",
    "    tf = train_data.targets == c\n",
    "    index = np.where(tf)[0]\n",
    "    centroid[c] = np.mean( np.take(train_data.inputs, index, axis=0), axis=0)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering(centroid, nr_clusters = 6):\n",
    "    \n",
    "    \n",
    "    centroid = np.array(centroid)\n",
    "    agg2 = AgglomerativeClustering(n_clusters=nr_clusters, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward')\n",
    "\n",
    "    \n",
    "    print(centroid.shape)\n",
    "    X = centroid.reshape(centroid.shape[0], centroid.shape[1]*centroid.shape[2]*centroid.shape[3])\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=4, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=seed)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    agg2.fit(X)\n",
    "    print('Done fitting\\n')\n",
    "\n",
    "    pred = agg2.fit_predict(X)\n",
    "    print('Done predicting\\n')\n",
    "\n",
    "\n",
    "    from itertools import cycle, islice\n",
    "    colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                                                 '#f781bf', '#a65628', '#984ea3',\n",
    "                                                 '#999999', '#e41a1c', '#dede00']),\n",
    "                                          int(max(pred) + 1))))\n",
    "\n",
    "    print(pred,X.shape)\n",
    "    plt.scatter(X[:, 0], X[:,1], s=34, color=colors[pred], marker='o')\n",
    "    plt.show()\n",
    "    new_labels_perDatapoint = new_labels(pred, nr_clusters)\n",
    "    return new_labels_perDatapoint\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key(mapped, c):\n",
    "    for k in mapped.keys():\n",
    "        if c in mapped[k]:\n",
    "            return k \n",
    "    raise Error('no matching class')\n",
    "\n",
    "\n",
    "def new_labels(pred, nr_clusters):\n",
    "    \n",
    "    '''mapped = {}\n",
    "    for sc in np.arange(nr_clusters):\n",
    "        tf = pred == sc\n",
    "        index = np.where(tf)[0]\n",
    "        mapped[sc] = index'''\n",
    "    \n",
    "    new_labels_perDatapoint = list(np.zeros(train_data.targets.shape))\n",
    "    for i in np.arange(train_data.inputs.shape[0]):\n",
    "        new_labels_perDatapoint[i] = pred[train_data.targets[i]]\n",
    "    \n",
    "    #print(new_labels_perDatapoint)\n",
    "    with open(\"./agg/clustering\" + str(nr_clusters) + \".pkl\", \"wb\") as g:\n",
    "        pickle.dump(new_labels_perDatapoint, g, -1 )\n",
    "\n",
    "    return new_labels_perDatapoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering(centroid, nr_clusters = 9)\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agg = AgglomerativeClustering(n_clusters=2, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward')\n",
    "\n",
    "n=2\n",
    "X = train_data.inputs.reshape(train_data.inputs.shape[0], train_data.inputs.shape[1]*train_data.inputs.shape[2]*train_data.inputs.shape[3])\n",
    "print(X[:n, :].shape, train_data.targets.shape)\n",
    "agg.fit(X[:n, :], y=train_data.targets[:n])\n",
    "print('Done fitting\\n')\n",
    "\n",
    "\n",
    "pred = agg.fit_predict(X[:n,:])\n",
    "print('Done predicting\\n')\n",
    "\n",
    "print(pred, train_data.targets[:n])\n",
    "print(sum(pred))\n",
    "\n",
    "#http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py\n",
    "\n",
    "from itertools import cycle, islice\n",
    "colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                                             '#f781bf', '#a65628', '#984ea3',\n",
    "                                             '#999999', '#e41a1c', '#dede00']),\n",
    "                                      int(max(pred) + 1))))\n",
    "\n",
    "n=200\n",
    "X1 = train_data.inputs[:n, :, : , :]\n",
    "plt.scatter(X1[:n, 0], X1[:n,1], s=4, color=colors[pred])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#print(centroid)\n",
    "\n",
    "\n",
    "#tf = train_data.targets == 100\n",
    "#index = np.where(tf)[0]\n",
    "#print(index)\n",
    "print(train_data.inputs.shape, index.shape)\n",
    "print(np.take(train_data.inputs, index, axis=0).shape)\n",
    "print(centroid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "centroid = list(np.zeros((100)))\n",
    "for c in np.arange(100):\n",
    "    tf = train_data.targets == c\n",
    "    index = np.where(tf)[0]\n",
    "    centroid[c] = np.mean( np.take(train_data.inputs, index, axis=0), axis=0)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def clustering(centroid, nr_clusters = 6):\n",
    "    \n",
    "    \n",
    "    centroid = np.array(centroid)\n",
    "    agg2 = AgglomerativeClustering(n_clusters=nr_clusters, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward')\n",
    "\n",
    "    \n",
    "    print(centroid.shape)\n",
    "    X = centroid.reshape(centroid.shape[0], centroid.shape[1]*centroid.shape[2]*centroid.shape[3])\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=4, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=seed)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    agg2.fit(X)\n",
    "    print('Done fitting\\n')\n",
    "\n",
    "    pred = agg2.fit_predict(X)\n",
    "    print('Done predicting\\n')\n",
    "\n",
    "\n",
    "    from itertools import cycle, islice\n",
    "    colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                                                 '#f781bf', '#a65628', '#984ea3',\n",
    "                                                 '#999999', '#e41a1c', '#dede00']),\n",
    "                                          int(max(pred) + 1))))\n",
    "\n",
    "    print(pred,X.shape)\n",
    "    plt.scatter(X[:, 0], X[:,1], s=34, color=colors[pred], marker='o')\n",
    "    plt.show()\n",
    "    new_labels(pred, nr_clusters)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in np.arange(2,3):\n",
    "    print(clustering(centroid, nr_clusters = 9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
